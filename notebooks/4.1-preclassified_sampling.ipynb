{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes pour le clustering pré-classifié"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Préparation du Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer Packages et Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jeanv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importer les packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  # Using NLTK to tokenize text\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation et Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le dataset 'DF_50_3000_DeDupl.xslx\n",
    "us_pol = pd.read_excel(r'C:\\Users\\jeanv\\Documents\\GitHub\\jun24_bc_llm\\data\\processed\\df_for_preclass_samples.xlsx')\n",
    "\n",
    "# Enlever les colonnes inutiles\n",
    "us_pol = us_pol.drop(['top_keywords', 'top_keywords_list', 'record', 'sign_count'], axis = 1)\n",
    "\n",
    "# renommer labels en topic\n",
    "us_pol = us_pol.rename(columns={'km_labels100': 'topic'})\n",
    "\n",
    "# Créer un nouveau dataframe avec que les 'short' et 'medium' pour le clustering\n",
    "us_pol_short = us_pol[us_pol['short_medium'] == 'short (50-280)']\n",
    "us_pol_medium = us_pol[us_pol['short_medium'] == 'medium (281-3000)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) Clustering Semi-Supervisé**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-fonction pour tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize text and get token count\n",
    "def count_tokens(text):\n",
    "    return len(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour le clustering de textes pré-classifiés (100 clusters, 1900 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topic_clusters(df, max_tokens_per_cluster=1900):\n",
    "    # Création du dataframe final\n",
    "    final_clusters = pd.DataFrame(columns=['cluster_id', 'clustered_text', 'id_50_3000', 'token_number', 'topic'])\n",
    "\n",
    "    # Extraire le nombre de topics\n",
    "    unique_topics = df['topic'].unique()\n",
    "\n",
    "    # Initialiser cluster ID\n",
    "    cluster_id = 1\n",
    "\n",
    "    # Loop par le nombre de topics pour créer un cluster initial\n",
    "    topic_clusters = {}\n",
    "    for topic in unique_topics:\n",
    "        # Filtrer df pour ne garder que les lignes liés au topic X\n",
    "        topic_df = df[df['topic'] == topic]\n",
    "\n",
    "        # Randomiser le dataframe filtrer\n",
    "        topic_df = topic_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Initialiser variables pour le clustering\n",
    "        cluster_text = \"\"\n",
    "        cluster_tokens = 0\n",
    "        clustered_ids = []\n",
    "\n",
    "        # Passer par chaque ligne du df lié au topic X\n",
    "        for index, row in topic_df.iterrows():\n",
    "            # Mise en format des textes dans le cluster\n",
    "            text = f\"- {row['text']}\\n\"\n",
    "            # Compter les tokens\n",
    "            text_tokens = count_tokens(text)\n",
    "            \n",
    "            # Vérifier si l'ajout du texte va au delà de la limite\n",
    "            if cluster_tokens + text_tokens > max_tokens_per_cluster:\n",
    "                break\n",
    "\n",
    "            # Ajouter le texte au cluster\n",
    "            cluster_text += text\n",
    "            # Ajouter nombre de tokens\n",
    "            cluster_tokens += text_tokens\n",
    "            # Ajouter id du texte utilisé\n",
    "            clustered_ids.append(str(row['id_50_3000']))\n",
    "\n",
    "        # Sauvegarder le cluster\n",
    "        topic_clusters[topic] = {\n",
    "            'clustered_text': cluster_text,\n",
    "            'id_50_3000': clustered_ids,\n",
    "            'token_number': cluster_tokens,\n",
    "            'topic': topic  # Add topic to the cluster\n",
    "        }\n",
    "\n",
    "    # Convert the final clusters to a dataframe\n",
    "    for topic, cluster in topic_clusters.items():\n",
    "        new_cluster = pd.DataFrame({\n",
    "            'cluster_id': [cluster_id],\n",
    "            'clustered_text': [cluster['clustered_text']],\n",
    "            'id_50_3000': [', '.join(cluster['id_50_3000'])],\n",
    "            'token_number': [cluster['token_number']],\n",
    "            'topic': [cluster['topic']]  # Add topic to the dataframe\n",
    "        })\n",
    "        final_clusters = pd.concat([final_clusters, new_cluster], ignore_index=True)\n",
    "        cluster_id += 1\n",
    "\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer fonction aux posts short et medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer fonctions aux short\n",
    "clusters_short = create_topic_clusters(us_pol_short)\n",
    "\n",
    "# Appliquer fonctions aux medium\n",
    "clusters_medium = create_topic_clusters(us_pol_medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Éliminer mauvais topics et id_50_3000 déjà utilisés du df original - *Pour les posts shorts* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clusters with more than 1000 tokens\n",
    "filtered_posts_short = clusters_short[clusters_short['token_number'] >= 1000]\n",
    "\n",
    "# Eliminer les topics qui ne sont pas bons\n",
    "bad_topics_short = clusters_short[clusters_short['token_number'] < 1000]['topic']\n",
    "us_pol_short_prefiltered = us_pol_short[~us_pol_short['topic'].isin(bad_topics_short)]\n",
    "\n",
    "# Eliminer les ids utilisées\n",
    "ids_to_remove = filtered_posts_short['id_50_3000'].str.split(', ').explode().astype(int).tolist()\n",
    "us_pol_short_filtered = us_pol_short_prefiltered[~us_pol_short_prefiltered['id_50_3000'].isin(ids_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Éliminer mauvais topics et id_50_3000 déjà utilisés du df original - *Pour les posts medium*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clusters with less than 1000 tokens\n",
    "filtered_posts_medium = clusters_medium[clusters_medium['token_number'] >= 1000]\n",
    "\n",
    "# Eliminer les topics qui ne sont pas bons\n",
    "bad_topics_medium = clusters_medium[clusters_medium['token_number'] < 1000]['topic']\n",
    "us_pol_medium_prefiltered = us_pol_medium[~us_pol_medium['topic'].isin(bad_topics_medium)]\n",
    "\n",
    "# Eliminer les ids utilisées\n",
    "ids_to_remove = filtered_posts_medium['id_50_3000'].str.split(', ').explode().astype(int).tolist()\n",
    "us_pol_medium_filtered = us_pol_medium_prefiltered[~us_pol_medium_prefiltered['id_50_3000'].isin(ids_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function on new dataframes and only select what is needed to reach total number  - *Pour les posts short*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer fonction sur df filtré short\n",
    "fill_clusters_short_pre = create_topic_clusters(us_pol_short_filtered)\n",
    "\n",
    "# Calculer combien de posts doivent être remplacés pour short\n",
    "tokens_deleted_short = len(clusters_short) - len(filtered_posts_short)\n",
    "\n",
    "# Garder que ce qui est nécessaire\n",
    "fill_clusters_short = fill_clusters_short_pre.head(tokens_deleted_short)\n",
    "\n",
    "# Concaténer pour avoir 100 posts\n",
    "final_clusters_short = pd.concat([filtered_posts_short, fill_clusters_short], ignore_index=True)\n",
    "\n",
    "# Only store first 100 rows\n",
    "final_clusters_short = final_clusters_short.head(100)\n",
    "\n",
    "# Ajouter une colonnes 'short' et combiner avec le 'cluster_id'\n",
    "final_clusters_short['type'] = 'short'\n",
    "final_clusters_short['cluster_id'] = ['PC_short_' + str(i) for i in range(1, len(final_clusters_short) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pour les posts medium*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer fonction sur df filtré medium\n",
    "fill_clusters_medium = create_topic_clusters(us_pol_medium_filtered)\n",
    "\n",
    "# Combien de clusters doivent être remplacés pour medium\n",
    "tokens_deleted_medium = len(clusters_medium) - len(filtered_posts_medium)\n",
    "\n",
    "# Garder que ce qui est nécessaire\n",
    "fill_clusters_medium = fill_clusters_medium.head(tokens_deleted_medium + 1)\n",
    "\n",
    "# Concaténer pour avoir 100 posts\n",
    "final_clusters_medium = pd.concat([filtered_posts_medium, fill_clusters_medium], ignore_index=True)\n",
    "\n",
    "# Ajouter une colonnes 'medium' et combiner avec le 'cluster_id'\n",
    "final_clusters_medium['type'] = 'medium'\n",
    "final_clusters_medium['cluster_id'] = ['PC_medium_' + str(i) for i in range(1, len(final_clusters_medium) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both 'short' and 'medium' dataframes together together\n",
    "preclassified_clusters = pd.concat([final_clusters_medium, final_clusters_short], axis=0, ignore_index=True)\n",
    "\n",
    "# Mettre R_medium\n",
    "preclassified_clusters['type'] = 'PC_' + preclassified_clusters['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>clustered_text</th>\n",
       "      <th>id_50_3000</th>\n",
       "      <th>token_number</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC_medium_1</td>\n",
       "      <td>- If you ve been wondering how long it would b...</td>\n",
       "      <td>24224, 62918, 9166, 43918</td>\n",
       "      <td>1795</td>\n",
       "      <td>50</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC_medium_2</td>\n",
       "      <td>- No Obama won t run again, but he ll use ever...</td>\n",
       "      <td>8818, 63900, 7791, 46741, 19417, 43478</td>\n",
       "      <td>1623</td>\n",
       "      <td>71</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC_medium_3</td>\n",
       "      <td>- The former CEO of a local cybersecurity firm...</td>\n",
       "      <td>23183, 38734, 51075, 33984, 32659</td>\n",
       "      <td>1606</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC_medium_4</td>\n",
       "      <td>- While most people have pretty much forgotten...</td>\n",
       "      <td>49550, 60236, 22597, 12450, 27174</td>\n",
       "      <td>1716</td>\n",
       "      <td>7</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PC_medium_5</td>\n",
       "      <td>- Donald Trump attacked the CEOs who are leavi...</td>\n",
       "      <td>4168, 58496, 56837, 4543</td>\n",
       "      <td>1741</td>\n",
       "      <td>81</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PC_medium_6</td>\n",
       "      <td>- LONDON (Reuters) - British Prime Minister Th...</td>\n",
       "      <td>20855, 27676, 49938, 49393, 37820</td>\n",
       "      <td>1784</td>\n",
       "      <td>37</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC_medium_7</td>\n",
       "      <td>- WASHINGTON (Reuters) - U.S. President Donald...</td>\n",
       "      <td>13654, 7576, 63091, 13529, 803</td>\n",
       "      <td>1854</td>\n",
       "      <td>57</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PC_medium_8</td>\n",
       "      <td>- GENEVA (Reuters) - A European and African de...</td>\n",
       "      <td>57964, 35796, 31868, 57540, 3129</td>\n",
       "      <td>1629</td>\n",
       "      <td>68</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PC_medium_9</td>\n",
       "      <td>- We re still waiting for the NFL to make a st...</td>\n",
       "      <td>15053, 42328, 43707, 57381</td>\n",
       "      <td>1836</td>\n",
       "      <td>60</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PC_medium_10</td>\n",
       "      <td>- FRANKFURT (Reuters) - A suspicious package t...</td>\n",
       "      <td>7021, 30333, 1299, 55277, 39271, 10429</td>\n",
       "      <td>1637</td>\n",
       "      <td>32</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PC_medium_11</td>\n",
       "      <td>- WASHINGTON (Reuters) - The chairman of the U...</td>\n",
       "      <td>60474, 38524, 43754, 52159, 40231, 47863</td>\n",
       "      <td>1663</td>\n",
       "      <td>67</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PC_medium_12</td>\n",
       "      <td>- For many, wildfire season has turned into a ...</td>\n",
       "      <td>1847, 32107, 46628, 14868, 43081, 11396, 46717...</td>\n",
       "      <td>1832</td>\n",
       "      <td>4</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PC_medium_13</td>\n",
       "      <td>- So....just got back from a real vacation on ...</td>\n",
       "      <td>63621, 55166, 39903, 55032, 24069, 39947, 6063...</td>\n",
       "      <td>1869</td>\n",
       "      <td>49</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PC_medium_14</td>\n",
       "      <td>- WASHINGTON (Reuters) - The U.S. Senate easil...</td>\n",
       "      <td>25215, 19623, 4434, 23041, 15728, 62073, 28728</td>\n",
       "      <td>1857</td>\n",
       "      <td>72</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PC_medium_15</td>\n",
       "      <td>- In 2016, Ben &amp; Jerry s co-founder, Ben Cohen...</td>\n",
       "      <td>32654, 25895, 37767, 25175, 36583, 49771, 6716...</td>\n",
       "      <td>1790</td>\n",
       "      <td>51</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PC_medium_16</td>\n",
       "      <td>- Blacks in America are seeing the writing on ...</td>\n",
       "      <td>325, 12011, 5208, 36835, 24056, 16661, 3059</td>\n",
       "      <td>1801</td>\n",
       "      <td>90</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PC_medium_17</td>\n",
       "      <td>- MADRID (Reuters) - Spain s state prosecutor ...</td>\n",
       "      <td>45820, 48042, 12491, 10041, 20615, 30692, 6356...</td>\n",
       "      <td>1563</td>\n",
       "      <td>86</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PC_medium_18</td>\n",
       "      <td>- For a long time now, the mainstream media ha...</td>\n",
       "      <td>2754, 51486, 25525, 60623</td>\n",
       "      <td>1570</td>\n",
       "      <td>91</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PC_medium_19</td>\n",
       "      <td>- TOKYO (Reuters) - NATO chief Jens Stoltenber...</td>\n",
       "      <td>61583, 44656, 30120, 52796, 51163, 42617, 31221</td>\n",
       "      <td>1773</td>\n",
       "      <td>44</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PC_medium_20</td>\n",
       "      <td>- WASHINGTON (Reuters) - President Donald Trum...</td>\n",
       "      <td>1416, 7048, 11608, 35540</td>\n",
       "      <td>1733</td>\n",
       "      <td>45</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster_id                                     clustered_text  \\\n",
       "0    PC_medium_1  - If you ve been wondering how long it would b...   \n",
       "1    PC_medium_2  - No Obama won t run again, but he ll use ever...   \n",
       "2    PC_medium_3  - The former CEO of a local cybersecurity firm...   \n",
       "3    PC_medium_4  - While most people have pretty much forgotten...   \n",
       "4    PC_medium_5  - Donald Trump attacked the CEOs who are leavi...   \n",
       "5    PC_medium_6  - LONDON (Reuters) - British Prime Minister Th...   \n",
       "6    PC_medium_7  - WASHINGTON (Reuters) - U.S. President Donald...   \n",
       "7    PC_medium_8  - GENEVA (Reuters) - A European and African de...   \n",
       "8    PC_medium_9  - We re still waiting for the NFL to make a st...   \n",
       "9   PC_medium_10  - FRANKFURT (Reuters) - A suspicious package t...   \n",
       "10  PC_medium_11  - WASHINGTON (Reuters) - The chairman of the U...   \n",
       "11  PC_medium_12  - For many, wildfire season has turned into a ...   \n",
       "12  PC_medium_13  - So....just got back from a real vacation on ...   \n",
       "13  PC_medium_14  - WASHINGTON (Reuters) - The U.S. Senate easil...   \n",
       "14  PC_medium_15  - In 2016, Ben & Jerry s co-founder, Ben Cohen...   \n",
       "15  PC_medium_16  - Blacks in America are seeing the writing on ...   \n",
       "16  PC_medium_17  - MADRID (Reuters) - Spain s state prosecutor ...   \n",
       "17  PC_medium_18  - For a long time now, the mainstream media ha...   \n",
       "18  PC_medium_19  - TOKYO (Reuters) - NATO chief Jens Stoltenber...   \n",
       "19  PC_medium_20  - WASHINGTON (Reuters) - President Donald Trum...   \n",
       "\n",
       "                                           id_50_3000 token_number topic  \\\n",
       "0                           24224, 62918, 9166, 43918         1795    50   \n",
       "1              8818, 63900, 7791, 46741, 19417, 43478         1623    71   \n",
       "2                   23183, 38734, 51075, 33984, 32659         1606     1   \n",
       "3                   49550, 60236, 22597, 12450, 27174         1716     7   \n",
       "4                            4168, 58496, 56837, 4543         1741    81   \n",
       "5                   20855, 27676, 49938, 49393, 37820         1784    37   \n",
       "6                      13654, 7576, 63091, 13529, 803         1854    57   \n",
       "7                    57964, 35796, 31868, 57540, 3129         1629    68   \n",
       "8                          15053, 42328, 43707, 57381         1836    60   \n",
       "9              7021, 30333, 1299, 55277, 39271, 10429         1637    32   \n",
       "10           60474, 38524, 43754, 52159, 40231, 47863         1663    67   \n",
       "11  1847, 32107, 46628, 14868, 43081, 11396, 46717...         1832     4   \n",
       "12  63621, 55166, 39903, 55032, 24069, 39947, 6063...         1869    49   \n",
       "13     25215, 19623, 4434, 23041, 15728, 62073, 28728         1857    72   \n",
       "14  32654, 25895, 37767, 25175, 36583, 49771, 6716...         1790    51   \n",
       "15        325, 12011, 5208, 36835, 24056, 16661, 3059         1801    90   \n",
       "16  45820, 48042, 12491, 10041, 20615, 30692, 6356...         1563    86   \n",
       "17                          2754, 51486, 25525, 60623         1570    91   \n",
       "18    61583, 44656, 30120, 52796, 51163, 42617, 31221         1773    44   \n",
       "19                           1416, 7048, 11608, 35540         1733    45   \n",
       "\n",
       "      type  \n",
       "0   medium  \n",
       "1   medium  \n",
       "2   medium  \n",
       "3   medium  \n",
       "4   medium  \n",
       "5   medium  \n",
       "6   medium  \n",
       "7   medium  \n",
       "8   medium  \n",
       "9   medium  \n",
       "10  medium  \n",
       "11  medium  \n",
       "12  medium  \n",
       "13  medium  \n",
       "14  medium  \n",
       "15  medium  \n",
       "16  medium  \n",
       "17  medium  \n",
       "18  medium  \n",
       "19  medium  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preclassified_clusters.to_excel('preclassified_clusters_V2.xlsx', index=False)\n",
    "final_clusters_medium.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
